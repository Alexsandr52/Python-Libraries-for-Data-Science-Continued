{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Для чего и в каких случаях полезны различные варианты усреднения для метрик качества классификации: micro, macro, weighted?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Варианты усреднения важны для того чтобы лучше оценивать предсказания в задачах с дисбалансом класcов. Micro подходит для задач не имеющих дисбаланса или имеющих не значительный дисбаланс, она похожа на accurase и решает ее проблемы. Macro для задач с сильным дисбалансом. Weighted для задач с большим количеством классов не сбалансированных между cобой, она дает дополнительный вес классу в зависимости от количества объектов относящихся к нему"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. В чём разница между моделями xgboost, lightgbm и catboost или какие их основные особенности?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В xgboost мы можем как регулировать глубину дерева так и отсикать листья. Дерево строится быстрее. lightgbm берем все наблюления с большой ошибкой и небольшую часть с маленькой ошибкой. расчетная часть алгоритма уменьшается в разы, скорость расчета вырастает, такой алгоритм нарушает распределение наблюлений. catboost на каждой итерации обучение и прогноз происхолят на разных выборках(сгенерированых)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "50292dbb1f747f7151d445135d392af3138fb3c65386d17d9510cb605222b10b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
